{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains ESC final results from 1956 to 2022.\n",
    "\n",
    "This notebook cleans the data and replaces categorical values with numeric ones and then applies machine learning to created dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>Year</th>\n",
       "      <th>Order</th>\n",
       "      <th>Country</th>\n",
       "      <th>Singer</th>\n",
       "      <th>Title</th>\n",
       "      <th>Points</th>\n",
       "      <th>Place</th>\n",
       "      <th>in_english</th>\n",
       "      <th>songid</th>\n",
       "      <th>lovementions</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Bobbejaan Schoepen</td>\n",
       "      <td>Straatdeuntje</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>11350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1957</td>\n",
       "      <td>2</td>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>DaniÃ¨le DuprÃ©</td>\n",
       "      <td>Tant De Peine</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>590667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1957</td>\n",
       "      <td>3</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Patricia Bredin</td>\n",
       "      <td>All</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>66020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1957</td>\n",
       "      <td>4</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Nunzio Gallo</td>\n",
       "      <td>Corde Della Mia Chitarra</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>60590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1957</td>\n",
       "      <td>5</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Bob Martin</td>\n",
       "      <td>Wohin Kleines Pony</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>8773000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>1369</td>\n",
       "      <td>2022</td>\n",
       "      <td>21</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Sheldon Riley</td>\n",
       "      <td>Not the Same</td>\n",
       "      <td>125</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>1369</td>\n",
       "      <td>0</td>\n",
       "      <td>24600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>1370</td>\n",
       "      <td>2022</td>\n",
       "      <td>22</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sam Ryder</td>\n",
       "      <td>Space Man</td>\n",
       "      <td>466</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>1370</td>\n",
       "      <td>0</td>\n",
       "      <td>66020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>1371</td>\n",
       "      <td>2022</td>\n",
       "      <td>23</td>\n",
       "      <td>Poland</td>\n",
       "      <td>Ochman</td>\n",
       "      <td>River</td>\n",
       "      <td>151</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>1371</td>\n",
       "      <td>0</td>\n",
       "      <td>37970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>1372</td>\n",
       "      <td>2022</td>\n",
       "      <td>24</td>\n",
       "      <td>Serbia</td>\n",
       "      <td>Konstrakta</td>\n",
       "      <td>In corpore sano</td>\n",
       "      <td>312</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>1372</td>\n",
       "      <td>0</td>\n",
       "      <td>7240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>1373</td>\n",
       "      <td>2022</td>\n",
       "      <td>25</td>\n",
       "      <td>Estonia</td>\n",
       "      <td>Stefan</td>\n",
       "      <td>Hope</td>\n",
       "      <td>141</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>1373</td>\n",
       "      <td>0</td>\n",
       "      <td>1316000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1359 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_id  Year  Order         Country              Singer  \\\n",
       "14         15  1957      1         Belgium  Bobbejaan Schoepen   \n",
       "15         16  1957      2      Luxembourg     DaniÃ¨le DuprÃ©   \n",
       "16         17  1957      3  United Kingdom     Patricia Bredin   \n",
       "17         18  1957      4           Italy        Nunzio Gallo   \n",
       "18         19  1957      5         Austria          Bob Martin   \n",
       "...       ...   ...    ...             ...                 ...   \n",
       "1368     1369  2022     21       Australia       Sheldon Riley   \n",
       "1369     1370  2022     22  United Kingdom           Sam Ryder   \n",
       "1370     1371  2022     23          Poland              Ochman   \n",
       "1371     1372  2022     24          Serbia          Konstrakta   \n",
       "1372     1373  2022     25         Estonia              Stefan   \n",
       "\n",
       "                         Title  Points  Place  in_english  songid  \\\n",
       "14               Straatdeuntje       5      8       False      15   \n",
       "15               Tant De Peine       8      5       False      16   \n",
       "16                         All       6      7        True      17   \n",
       "17    Corde Della Mia Chitarra       7      6       False      18   \n",
       "18          Wohin Kleines Pony       3     10       False      19   \n",
       "...                        ...     ...    ...         ...     ...   \n",
       "1368              Not the Same     125     15        True    1369   \n",
       "1369                 Space Man     466      2        True    1370   \n",
       "1370                     River     151     12        True    1371   \n",
       "1371           In corpore sano     312      5       False    1372   \n",
       "1372                      Hope     141     13        True    1373   \n",
       "\n",
       "      lovementions  population  \n",
       "14               0    11350000  \n",
       "15               5      590667  \n",
       "16               1    66020000  \n",
       "17               0    60590000  \n",
       "18               0     8773000  \n",
       "...            ...         ...  \n",
       "1368             0    24600000  \n",
       "1369             0    66020000  \n",
       "1370             0    37970000  \n",
       "1371             0     7240000  \n",
       "1372             0     1316000  \n",
       "\n",
       "[1359 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/ESCDB2.csv\", sep=\";\", encoding=\"latin-1\")\n",
    "\n",
    "# Removing potential unneccesary spaces from dataframe columns\n",
    "for column in data.select_dtypes(include='object'):\n",
    "    data[column] = data[column].str.strip()\n",
    "\n",
    "# Dropping duplicate column \"songid\"\n",
    "data.drop('songid', axis=1)\n",
    "\n",
    "# Dropping 1956 contest result, since no points/places were awarded except the winner\n",
    "# Simply dropping this data should not affect the results because the contest was nothing like the \n",
    "# current and the points system was also different beyond recognition\n",
    "data = data.drop(data[data['Year'] == 1956].index)\n",
    "\n",
    "# Replacing \"Macedonia\" with \"North Macedonia\", since the country changed its name\n",
    "data[\"Country\"] = data[\"Country\"].replace(\"Macedonia\", \"North Macedonia\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making era column based on years:\n",
    "\n",
    "- years 1957-1986 -> 0 (very old contests)\n",
    "- years 1987-1999 -> 1 (roughly after soviet union collapse)\n",
    "- years 2000-2013 -> 2 (prior to invasion of ukraine)\n",
    "- years 2014-2022 -> 3 (modern era of the contest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def era(row):\n",
    "    if row[\"Year\"] >= 1957 and row[\"Year\"] <= 1986:\n",
    "        return 0\n",
    "    if row[\"Year\"] >= 1987 and row[\"Year\"] <= 1999:\n",
    "        return 1\n",
    "    if row[\"Year\"] >= 2000 and row[\"Year\"] <= 2013:\n",
    "        return 2\n",
    "    if row[\"Year\"] >= 2014 and row[\"Year\"] <= 2022:\n",
    "        return 3\n",
    "    \n",
    "data[\"Era\"] = data.apply(lambda row: era(row), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making country column numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = data[\"Country\"].unique()\n",
    "countries.sort()\n",
    "\n",
    "countries_to_numbers = {}\n",
    "\n",
    "for i in range(len(countries)):\n",
    "    countries_to_numbers[countries[i]] = i\n",
    "\n",
    "data[\"Country\"] = data[\"Country\"].map(countries_to_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the singer column numeric\n",
    "\n",
    "This will be a boolean value:\n",
    "* **0** if the singer has only performed once in ESC\n",
    "* **1** if the singer has performed multiple times in ESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Singer\"] = data[\"Singer\"].map(lambda x: 0 if data[\"Singer\"].value_counts()[x] == 1 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making title column numeric.\n",
    "\n",
    "We are extracting two attributes:\n",
    "* 1 if song title included word \"Love\" 0 otherwise\n",
    "* 1 if song title is more than 1 word, 0 otherwise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"love_in_title\"] = data[\"Title\"].map(lambda x: 1 if 'love' in x.lower() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Title\"] = data[\"Title\"].map(lambda x: len(x.split()))\n",
    "data = data.rename(columns={\"Title\" : \"title_word_count\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making \"in_english\" column numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"in_english\"] = data[\"in_english\"].map(lambda x: 1 if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>Year</th>\n",
       "      <th>Order</th>\n",
       "      <th>Country</th>\n",
       "      <th>Singer</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>Points</th>\n",
       "      <th>Place</th>\n",
       "      <th>in_english</th>\n",
       "      <th>songid</th>\n",
       "      <th>lovementions</th>\n",
       "      <th>population</th>\n",
       "      <th>Era</th>\n",
       "      <th>love_in_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>11350000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1957</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>590667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1957</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>66020000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1957</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>60590000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1957</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>8773000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>1369</td>\n",
       "      <td>2022</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>125</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1369</td>\n",
       "      <td>0</td>\n",
       "      <td>24600000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>1370</td>\n",
       "      <td>2022</td>\n",
       "      <td>22</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>466</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1370</td>\n",
       "      <td>0</td>\n",
       "      <td>66020000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>1371</td>\n",
       "      <td>2022</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1371</td>\n",
       "      <td>0</td>\n",
       "      <td>37970000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>1372</td>\n",
       "      <td>2022</td>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>312</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1372</td>\n",
       "      <td>0</td>\n",
       "      <td>7240000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>1373</td>\n",
       "      <td>2022</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1373</td>\n",
       "      <td>0</td>\n",
       "      <td>1316000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1359 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      song_id  Year  Order  Country  Singer  title_word_count  Points  Place  \\\n",
       "14         15  1957      1        6       0                 1       5      8   \n",
       "15         16  1957      2       26       0                 3       8      5   \n",
       "16         17  1957      3       49       0                 1       6      7   \n",
       "17         18  1957      4       23       0                 4       7      6   \n",
       "18         19  1957      5        3       0                 3       3     10   \n",
       "...       ...   ...    ...      ...     ...               ...     ...    ...   \n",
       "1368     1369  2022     21        2       0                 3     125     15   \n",
       "1369     1370  2022     22       49       0                 2     466      2   \n",
       "1370     1371  2022     23       35       0                 1     151     12   \n",
       "1371     1372  2022     24       40       0                 3     312      5   \n",
       "1372     1373  2022     25       13       0                 1     141     13   \n",
       "\n",
       "      in_english  songid  lovementions  population  Era  love_in_title  \n",
       "14             0      15             0    11350000    0              0  \n",
       "15             0      16             5      590667    0              0  \n",
       "16             1      17             1    66020000    0              0  \n",
       "17             0      18             0    60590000    0              0  \n",
       "18             0      19             0     8773000    0              0  \n",
       "...          ...     ...           ...         ...  ...            ...  \n",
       "1368           1    1369             0    24600000    3              0  \n",
       "1369           1    1370             0    66020000    3              0  \n",
       "1370           1    1371             0    37970000    3              0  \n",
       "1371           0    1372             0     7240000    3              0  \n",
       "1372           1    1373             0     1316000    3              0  \n",
       "\n",
       "[1359 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display out the result\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14       8\n",
      "15       5\n",
      "16       7\n",
      "17       6\n",
      "18      10\n",
      "        ..\n",
      "1368    15\n",
      "1369     2\n",
      "1370    12\n",
      "1371     5\n",
      "1372    13\n",
      "Name: Place, Length: 1359, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# unneccesary column\n",
    "data = data.drop('song_id', axis=1)\n",
    "\n",
    "# not needed\n",
    "place_data = data['Place']\n",
    "print(place_data)\n",
    "data = data.drop(columns=['Place'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and functions needed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import neighbors\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(list):\n",
    "  sum = 0\n",
    "  for num in list:\n",
    "    sum += num\n",
    "\n",
    "  return sum / len(list)\n",
    "\n",
    "def top10accuracy(result):\n",
    "    real_top10 = []\n",
    "    pred_top10 = []\n",
    "    o = 0\n",
    "    for i in range(10):\n",
    "        o+=1\n",
    "        real_top10.append(result.loc[result['actual_place'] == o, 'Country'].iloc[0])\n",
    "        pred_top10.append(result.loc[result['pred_place'] == o, 'Country'].iloc[0])\n",
    "    #Create a counter for the number of elements that match\n",
    "    accuracy_count = 0\n",
    "    #Loop through both lists and check if the elements are equal and have the same index\n",
    "    for country in pred_top10:\n",
    "        if country in real_top10:\n",
    "            accuracy_count += 1\n",
    "    #Calculate the accuracy of the two lists\n",
    "    accuracy = accuracy_count/len(real_top10)\n",
    "    print(\"quessed top 10 countries with\", accuracy*100, \"% accuracy\")\n",
    "    return accuracy\n",
    "\n",
    "def top3accuracy(result):\n",
    "    real_top3 = []\n",
    "    pred_top3 = []\n",
    "    o = 0\n",
    "    for i in range(3):\n",
    "        o+=1\n",
    "        real_top3.append(result.loc[result['actual_place'] == o, 'Country'].iloc[0])\n",
    "        pred_top3.append(result.loc[result['pred_place'] == o, 'Country'].iloc[0])\n",
    "    #Create a counter for the number of elements that match\n",
    "    accuracy_count = 0\n",
    "    #Loop through both lists and check if the elements are equal and have the same index\n",
    "    for country in pred_top3:\n",
    "        if country in real_top3:\n",
    "            accuracy_count += 1\n",
    "    #Calculate the accuracy of the two lists\n",
    "    accuracy = accuracy_count/len(real_top3)\n",
    "    print(\"quessed top 3 countries with\", accuracy*100, \"% accuracy\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_pred, X_test, countries_to_numbers, classifier_name, X_test_points):\n",
    "    numbers_to_countries = dict((v, k) for k, v in countries_to_numbers.items())\n",
    "\n",
    "    result = X_test.iloc[:, [2, 5]]\n",
    "\n",
    "    result[\"Country\"] = result[\"Country\"].map(numbers_to_countries)\n",
    "    result = result.assign(Predicted=list(y_pred))\n",
    "\n",
    "    result = result.sort_values(\"Predicted\", ascending=False)\n",
    "    result = result.assign(pred_place=range(1, len(result) + 1))\n",
    "    \n",
    "    result['Points'] = X_test_points\n",
    "\n",
    "    result = result.sort_values(\"Points\", ascending=False)\n",
    "    result = result.assign(actual_place=range(1, len(result) + 1))\n",
    "\n",
    "    result[\"correct\"] = abs(result[\"pred_place\"] - result[\"actual_place\"])\n",
    "    result[\"correct\"] = result[\"correct\"].apply(lambda x: x <= 0)\n",
    "\n",
    "    print(classifier_name, \"classifiers results were:\")\n",
    "    #print(result)\n",
    "    score = result[\"correct\"].value_counts(\"True\")\n",
    "\n",
    "    print(score)\n",
    "    top10acc = top10accuracy(result)\n",
    "    top3acc = top3accuracy(result)\n",
    "    return score, top3acc, top10acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importantFeatures(classifier):\n",
    "    # Get the feature importances from the trained model\n",
    "    importances = classifier.feature_importances_\n",
    "\n",
    "    # Sort the feature importances in descending order\n",
    "    sorted_importances = sorted(importances, reverse=True)\n",
    "\n",
    "    # Print the least important features\n",
    "    least_important_feature = sorted_importances[-1:][0]\n",
    "    most_important_feature = sorted_importances[0]\n",
    "    attributes = list(data)\n",
    "    s = sorted(zip(importances, attributes), reverse=True)\n",
    "    print(get_other_part(s, least_important_feature), \"was the least important feature\")\n",
    "    print(get_other_part(s, most_important_feature), \"was the most important feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def trainAndTest(classifier, classifier_name, years_to_predict, data):\n",
    "    scores = []\n",
    "    top3accs = []\n",
    "    top10accs = []\n",
    "    \n",
    "    for year_to_predict in years_to_predict:\n",
    "        y = data.iloc[:, [0, 5]] # year | points\n",
    "\n",
    "        # trying to predict 2018\n",
    "        y_train = y[y[\"Year\"] != year_to_predict][\"Points\"] # y_train\n",
    "        y_test = y[y[\"Year\"] == year_to_predict][\"Points\"]  # y_test\n",
    "\n",
    "        X_train = data[data[\"Year\"] != year_to_predict]     # X_train\n",
    "        X_test = data[data[\"Year\"] == year_to_predict]      # X_test\n",
    "        \n",
    "        X_train_points = X_train['Points']                  #keep points\n",
    "        X_test_points = X_test['Points']                    #keep points\n",
    "        \n",
    "        X_train = X_train.drop(columns=['Points'])\n",
    "        X_test = X_test.drop(columns=['Points'])\n",
    "\n",
    "        classifier.fit(X_train, y_train)\n",
    "            \n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        print(year_to_predict, \"results:\")\n",
    "        score, top3acc, top10acc = evaluate(y_pred, X_test, countries_to_numbers, classifier_name, X_test_points)\n",
    "        scores.append(score)\n",
    "        top3accs.append(top3acc)\n",
    "        top10accs.append(top10acc)\n",
    "        \n",
    "    average_score = average(scores)\n",
    "    average_top3acc = average(top3accs)\n",
    "    average_top10acc = average(top10accs)\n",
    "    \n",
    "    if classifier_name == \"Random Forest\":\n",
    "        importantFeatures(classifier)\n",
    "    \n",
    "    print(classifier_name)\n",
    "    print(\"average accuracy for certain countries place was:\", average_score)\n",
    "    print(\"average top10accuracy was:\", average_top10acc)\n",
    "    print(\"average top3accuracy was:\", average_top3acc)\n",
    "    \n",
    "    return average_score, average_top3acc, average_top10acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(strings):\n",
    "  # Create a dictionary to keep track of the number of occurrences of each string\n",
    "  counts = {}\n",
    "\n",
    "  # Iterate over the list of strings\n",
    "  for string in strings:\n",
    "    # If the string is not in the dictionary, add it with a count of 1\n",
    "    if string not in counts:\n",
    "      counts[string] = 1\n",
    "    # Otherwise, increment the count for that string\n",
    "    else:\n",
    "      counts[string] += 1\n",
    "\n",
    "  # Find the string with the highest count\n",
    "  most_frequent_string = None\n",
    "  highest_count = 0\n",
    "  for string, count in counts.items():\n",
    "    if count > highest_count:\n",
    "      most_frequent_string = string\n",
    "      highest_count = count\n",
    "\n",
    "  return most_frequent_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_other_part(duples, part):\n",
    "  # Iterate over the list of duples\n",
    "  for duple in duples:\n",
    "    # If the duple contains the given part, return the other part\n",
    "    if part in duple:\n",
    "      return [x for x in duple if x != part][0]\n",
    "\n",
    "  # If no duple contains the given part, return None\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "  # If n is less than or equal to 1, return 1\n",
    "  if n <= 1:\n",
    "    return 1\n",
    "\n",
    "  # Otherwise, return the product of n and the factorial of n-1\n",
    "  return n * factorial(n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating, training and testing classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987 results:\n",
      "KNN classifiers results were:\n",
      "False    0.909091\n",
      "True     0.090909\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "1996 results:\n",
      "KNN classifiers results were:\n",
      "False    0.913043\n",
      "True     0.086957\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 60.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2001 results:\n",
      "KNN classifiers results were:\n",
      "False    0.956522\n",
      "True     0.043478\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "2016 results:\n",
      "KNN classifiers results were:\n",
      "False    0.846154\n",
      "True     0.153846\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 60.0 % accuracy\n",
      "quessed top 3 countries with 66.66666666666666 % accuracy\n",
      "2017 results:\n",
      "KNN classifiers results were:\n",
      "False    0.923077\n",
      "True     0.076923\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 80.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2018 results:\n",
      "KNN classifiers results were:\n",
      "False    0.923077\n",
      "True     0.076923\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 40.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "2019 results:\n",
      "KNN classifiers results were:\n",
      "False    0.961538\n",
      "True     0.038462\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 70.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2021 results:\n",
      "KNN classifiers results were:\n",
      "False    0.923077\n",
      "True     0.076923\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 30.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2022 results:\n",
      "KNN classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "KNN\n",
      "average accuracy for certain countries place was: False    0.928398\n",
      "True          NaN\n",
      "Name: correct, dtype: float64\n",
      "average top10accuracy was: 0.5444444444444444\n",
      "average top3accuracy was: 0.25925925925925924\n",
      "1987 results:\n",
      "Random Forest classifiers results were:\n",
      "False    0.909091\n",
      "True     0.090909\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "1996 results:\n",
      "Random Forest classifiers results were:\n",
      "False    0.869565\n",
      "True     0.130435\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 66.66666666666666 % accuracy\n",
      "2001 results:\n",
      "Random Forest classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "2016 results:\n",
      "Random Forest classifiers results were:\n",
      "False    0.961538\n",
      "True     0.038462\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 40.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2017 results:\n",
      "Random Forest classifiers results were:\n",
      "False    0.961538\n",
      "True     0.038462\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 40.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "2018 results:\n",
      "Random Forest classifiers results were:\n",
      "False    0.961538\n",
      "True     0.038462\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 30.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "2019 results:\n",
      "Random Forest classifiers results were:\n",
      "False    0.961538\n",
      "True     0.038462\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2021 results:\n",
      "Random Forest classifiers results were:\n",
      "False    0.961538\n",
      "True     0.038462\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2022 results:\n",
      "Random Forest classifiers results were:\n",
      "False    0.96\n",
      "True     0.04\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 30.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "Era was the least important feature\n",
      "in_english was the most important feature\n",
      "Random Forest\n",
      "average accuracy for certain countries place was: False    0.949594\n",
      "True          NaN\n",
      "Name: correct, dtype: float64\n",
      "average top10accuracy was: 0.4333333333333333\n",
      "average top3accuracy was: 0.2222222222222222\n",
      "1987 results:\n",
      "SVM(rbf) classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 60.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "1996 results:\n",
      "SVM(rbf) classifiers results were:\n",
      "False    0.956522\n",
      "True     0.043478\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 20.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "2001 results:\n",
      "SVM(rbf) classifiers results were:\n",
      "False    0.956522\n",
      "True     0.043478\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 70.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "2016 results:\n",
      "SVM(rbf) classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 40.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2017 results:\n",
      "SVM(rbf) classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 40.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2018 results:\n",
      "SVM(rbf) classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 40.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2019 results:\n",
      "SVM(rbf) classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 60.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2021 results:\n",
      "SVM(rbf) classifiers results were:\n",
      "False    0.961538\n",
      "True     0.038462\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2022 results:\n",
      "SVM(rbf) classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "SVM(rbf)\n",
      "average accuracy for certain countries place was: False    0.986065\n",
      "Name: correct, dtype: float64\n",
      "average top10accuracy was: 0.47777777777777775\n",
      "average top3accuracy was: 0.2222222222222222\n",
      "1987 results:\n",
      "Lasso classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 40.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "1996 results:\n",
      "Lasso classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 30.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2001 results:\n",
      "Lasso classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 60.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "2016 results:\n",
      "Lasso classifiers results were:\n",
      "False    0.961538\n",
      "True     0.038462\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 30.0 % accuracy\n",
      "quessed top 3 countries with 66.66666666666666 % accuracy\n",
      "2017 results:\n",
      "Lasso classifiers results were:\n",
      "False    0.923077\n",
      "True     0.076923\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "2018 results:\n",
      "Lasso classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "2019 results:\n",
      "Lasso classifiers results were:\n",
      "False    0.884615\n",
      "True     0.115385\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2021 results:\n",
      "Lasso classifiers results were:\n",
      "False    0.961538\n",
      "True     0.038462\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 40.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2022 results:\n",
      "Lasso classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "Lasso\n",
      "average accuracy for certain countries place was: False    0.970085\n",
      "Name: correct, dtype: float64\n",
      "average top10accuracy was: 0.4444444444444444\n",
      "average top3accuracy was: 0.25925925925925924\n",
      "1987 results:\n",
      "Ridge classifiers results were:\n",
      "False    0.863636\n",
      "True     0.136364\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 40.0 % accuracy\n",
      "quessed top 3 countries with 66.66666666666666 % accuracy\n",
      "1996 results:\n",
      "Ridge classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quessed top 10 countries with 30.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2001 results:\n",
      "Ridge classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 60.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "2016 results:\n",
      "Ridge classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 30.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2017 results:\n",
      "Ridge classifiers results were:\n",
      "False    0.923077\n",
      "True     0.076923\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "2018 results:\n",
      "Ridge classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "2019 results:\n",
      "Ridge classifiers results were:\n",
      "False    0.961538\n",
      "True     0.038462\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 50.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "2021 results:\n",
      "Ridge classifiers results were:\n",
      "False    0.961538\n",
      "True     0.038462\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 40.0 % accuracy\n",
      "quessed top 3 countries with 0.0 % accuracy\n",
      "2022 results:\n",
      "Ridge classifiers results were:\n",
      "False    1.0\n",
      "Name: correct, dtype: float64\n",
      "quessed top 10 countries with 40.0 % accuracy\n",
      "quessed top 3 countries with 33.33333333333333 % accuracy\n",
      "Ridge\n",
      "average accuracy for certain countries place was: False    0.967754\n",
      "True          NaN\n",
      "Name: correct, dtype: float64\n",
      "average top10accuracy was: 0.4333333333333333\n",
      "average top3accuracy was: 0.2222222222222222\n",
      "\n",
      "\n",
      "averages across all models:\n",
      "1) average score: False    0.960379\n",
      "True          NaN\n",
      "Name: correct, dtype: float64\n",
      "2) average top 10 accuracy: 0.4666666666666666\n",
      "3) average top 3 accuracy: 0.23703703703703702\n"
     ]
    }
   ],
   "source": [
    "years_to_predict = [1987, 1996, 2001, 2016, 2017, 2018, 2019, 2021, 2022]\n",
    "\n",
    "\n",
    "classifier1 = neighbors.KNeighborsClassifier(n_neighbors = 5)\n",
    "classifier1_name = \"KNN\"\n",
    "classifier2 = RandomForestClassifier()\n",
    "classifier2_name = \"Random Forest\"\n",
    "classifier3 = SVC(kernel=\"rbf\")\n",
    "classifier3_name = \"SVM(rbf)\"\n",
    "classifier4 = Lasso() # SEE ANNAB 100% õiged?\n",
    "classifier4_name = \"Lasso\"\n",
    "classifier5 = Ridge() # ka 100% õiged?\n",
    "classifier5_name = \"Ridge\"\n",
    "\n",
    "classifiers = [classifier1, classifier2, classifier3, classifier4, classifier5]\n",
    "classifier_names = [classifier1_name, classifier2_name, classifier3_name, classifier4_name, classifier5_name]\n",
    "\n",
    "datasets = []\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    data2 = data\n",
    "    datasets.append(data2)\n",
    "\n",
    "average_across_score = []\n",
    "average_across_top3acc = [] \n",
    "average_across_top10acc = []\n",
    "\n",
    "for i in range(len(classifiers)):\n",
    "    average_score, average_top3acc, average_top10acc = trainAndTest(classifiers[i], classifier_names[i], years_to_predict, datasets[i])\n",
    "    average_across_score.append(average_score)\n",
    "    average_across_top3acc.append(average_top3acc)\n",
    "    average_across_top10acc.append(average_top10acc)\n",
    "\n",
    "average_across_score = average(average_across_score)\n",
    "average_across_top3acc = average(average_across_top3acc)\n",
    "average_across_top10acc = average(average_across_top10acc)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"averages across all models:\")\n",
    "print(\"1) average score:\", average_across_score)\n",
    "print(\"2) average top 10 accuracy:\", average_across_top10acc)\n",
    "print(\"3) average top 3 accuracy:\", average_across_top3acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The least important feature was era and the most important feature was in_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0b62f3ea622981e42fd1daffea03d8fc6d29121cf9f580f862b48f39b37f2dfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
